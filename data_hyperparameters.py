from torch.cuda import is_available

VOCAB_SIZE = 10000
TOKENIZER = "spacy"
BATCH_SIZE = 32
TRAIN_VALID_SPLIT = 0.1
PATIENCE = 5
STATISTICS_FILE = 'statistics.csv'
USE_CUDA = is_available()
EMBEDDING_DIMENSION = 100
EPOCHS = 10
MIN_REVIEW_LENGTH = 10
CONTEXT_SIZE = 3
UNIGRAM_DISTRIBUTION_POWER = 0.75
NUM_NEGATIVE_SAMPLES = 10
INNER_PRODUCT_CLAMP = 4.
SUBSAMPLE_THRESHOLD = 1e-4
WORD_EMBEDDING_DIMENSION = 20
VERBOSE_LOGGING = False
TRAIN_PROPORTION = 0.9
WORD_EMBEDDING_BATCH_SIZE = 128
WORD_EMBEDDING_EPOCHS = 5
